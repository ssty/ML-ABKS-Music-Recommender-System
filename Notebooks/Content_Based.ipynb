{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(r\"datasets/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 15701)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer( stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "tracks['name'] = tracks['name'].fillna('')\n",
    "\n",
    "tracks = tracks.head(25000)\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(tracks['name'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices = pd.Series(tracks.index, index=tracks['name']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    idx = indices[title]\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    track_indices = [i[0] for i in sim_scores]\n",
    "    return tracks['name'].iloc[track_indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fall Back Down',\n",
       " 'Fall For You',\n",
       " 'I Might Fall Back On You',\n",
       " 'When I Fall In Love',\n",
       " 'When I Fall In Love',\n",
       " 'When I Fall In Love',\n",
       " 'When I Fall In Love',\n",
       " 'If I Ever Fall In Love',\n",
       " 'If I Ever Fall In Love',\n",
       " 'I Could Fall In Love']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"I Might Fall Back On You\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.to_csv('tracks_with_cluster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spotipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0851234b81a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspotipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspotipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moauth2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpotifyClientCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"677a46ed628944af94b5cdb96e3e25ee\",\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spotipy'"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"677a46ed628944af94b5cdb96e3e25ee\",\n",
    "                                                           client_secret=\"dfc3a58da7e34b009001ff1794592060\"))\n",
    "\n",
    "def find_song(name):\n",
    "    song_data = defaultdict()\n",
    "    results = sp.search(q= 'track: {}'.format(name), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "\n",
    "    results = results['tracks']['items'][0]\n",
    "    track_id = results['id']\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "\n",
    "    song_data['name'] = [name]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "    song_data['duration_ms'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "\n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "\n",
    "    return pd.DataFrame(song_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_data(song, spotify_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets the song data for a specific song. The song argument takes the form of a dictionary with \n",
    "    key-value pairs for the name and release year of the song.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['name'] == song['name']) ].iloc[0]\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError:\n",
    "        return find_song(song['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_algorithm(tracks):\n",
    "    num_datatypes = tracks.select_dtypes(np.number)      \n",
    "\n",
    "    pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "    song_embedding = pca_pipeline.fit_transform(num_datatypes)\n",
    "    return song_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_with_PCA_algorithm(song_embedding):\n",
    "    kmeans_pca = KMeans(n_clusters = 3, init = 'k-means++', random_state=42)    \n",
    "    return kmeans_pca.fit(song_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_based_on_segment(df_segm_pca_kmeans,segment_val):    \n",
    "    #get list of songs with above song id\n",
    "    #print(df_segm_pca_kmeans[df_segm_pca_kmeans['Segment K-means PCA']==segment_val].values)\n",
    "    \n",
    "    filtered_data_per_segment = df_segm_pca_kmeans[df_segm_pca_kmeans['Segment K-means PCA']==segment_val][['id', 'name','com1','com2','Segment K-means PCA']]\n",
    "\n",
    "    #save to csv file\n",
    "    filtered_data_per_segment.to_csv('filtered_data_per_segment.csv')\n",
    "    return filtered_data_per_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_based_on_cluster_centroid(kmeans_pca,filtered_data_per_segment,segment_val,tracks):\n",
    "    #calculate distance based on cluster centroid\n",
    "    scaled_data = kmeans_pca.transform( filtered_data_per_segment[['com1','com2']])\n",
    "    scaled_song_center = kmeans_pca.transform(kmeans_pca.cluster_centers_[segment_val].reshape(1, -1))\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "\n",
    "    #sort based on distance\n",
    "    index = list(np.argsort(distances)[0])\n",
    "    rec_songs = filtered_data_per_segment.iloc[index]\n",
    "    \n",
    "    #recommend based on segment data\n",
    "    # rec_songs = rec_songs[~rec_songs['name'].isin(filtered_data_per_segment['name'])]\n",
    "    return rec_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def recommend_songs(song_id, n_songs=10):\n",
    "  \n",
    "    \"\"\"\n",
    "    Recommends songs based on a list of previous songs that a user has listened to.\n",
    "    \"\"\"\n",
    "    song_embedding = PCA_algorithm(tracks)\n",
    "    \n",
    "    kmeans_pca = KMeans_with_PCA_algorithm(song_embedding)\n",
    "\n",
    "    #get Segment K-means PCA from song_id argument\n",
    "    df_segm_pca_kmeans = pd.concat([tracks.reset_index(drop=True), pd.DataFrame(song_embedding)],axis=1)\n",
    "    df_segm_pca_kmeans.columns.values[-2:] = ['com1','com2']\n",
    "    df_segm_pca_kmeans['Segment K-means PCA'] = kmeans_pca.labels_\n",
    "\n",
    "    #get segment value of song_id\n",
    "    segment_val = df_segm_pca_kmeans[df_segm_pca_kmeans['id'] == song_id]['Segment K-means PCA'].values[0]\n",
    "    \n",
    "    filtered_data_per_segment = filter_based_on_segment(df_segm_pca_kmeans,segment_val)   \n",
    "    \n",
    "    X = filtered_data_per_segment['com1']\n",
    "    y = filtered_data_per_segment['com2']\n",
    "    print(filtered_data_per_segment)\n",
    "\n",
    "    rec_songs = filter_based_on_cluster_centroid(kmeans_pca,filtered_data_per_segment,segment_val,tracks)\n",
    "\n",
    "    #recommend top n songs\n",
    "    return rec_songs.head(n_songs)['name'].tolist(), X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           id                             name      com1  \\\n",
      "1      7xPhfUan2yNtyFG0cUWkt8          Clancy Lowered the Boom  1.050906   \n",
      "9      08zfJvRLp7pjAb94MA9JmF                Il Etait Syndiqu√©  1.881899   \n",
      "10     0BMkRpQtDoKjcgzCpnqLNa  Dans La Vie Faut Pas S'en Faire  2.171411   \n",
      "14     0MJZ4hh60zwsYleWWxT5yW                   Power Is Power -0.690042   \n",
      "18     0QQmUf4aPFaN9U2yRko595                      When We Die  0.335485   \n",
      "...                       ...                              ...       ...   \n",
      "24989  6MMF38qO03XJ7puIxVl8Gg         I Might Fall Back On You  0.777417   \n",
      "24990  6SUXMuSUM01Ou6FRwKXyIc             Ella...La Que Se Fue  0.084604   \n",
      "24994  6kQ6pAESTDPwq1ZWrNHU42         Life On the Wicked Stage  1.696521   \n",
      "24998  7CZhyjk2lDW7A0lRsig45j    Where Will I Shelter My Sheep  0.999716   \n",
      "24999  7DvMNdb2kACIW4mO3MUqa3                         Cherokee  0.874801   \n",
      "\n",
      "           com2  Segment K-means PCA  \n",
      "1     -2.821883                    1  \n",
      "9     -2.385203                    1  \n",
      "10    -0.909158                    1  \n",
      "14    -1.172696                    1  \n",
      "18    -0.631702                    1  \n",
      "...         ...                  ...  \n",
      "24989 -1.213022                    1  \n",
      "24990 -0.154568                    1  \n",
      "24994 -0.226532                    1  \n",
      "24998 -0.687640                    1  \n",
      "24999 -0.054087                    1  \n",
      "\n",
      "[7662 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "rec_song, X, y = recommend_songs(\"3w3cxwYuR7ThpE8KVSys5x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listFrom1toN(n):\n",
    "    return list(range(1,n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7662\n",
      "7662\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 7662",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-c8730abdb372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 7662"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "result = np.vstack((X, y)).T\n",
    "\n",
    "X = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.05090562 -2.82188307]\n",
      " [ 1.88189933 -2.38520321]\n",
      " [ 2.17141059 -0.90915789]\n",
      " ...\n",
      " [ 1.69652077 -0.22653163]\n",
      " [ 0.99971613 -0.68764005]\n",
      " [ 0.87480095 -0.05408667]]\n",
      "7662\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "n = len(result)\n",
    "print(n)\n",
    "y = listFrom1toN(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# fig = px.scatter(projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r\"C:/Users/shris/Desktop/profiles.csv\")\n",
    "# print(df.gender)\n",
    "# df.columns = ['userid', 'gender', 'age', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs = df.gender.tolist()\n",
    "# output = {}\n",
    "# outputs = []\n",
    "# for song in songs:\n",
    "#     k = recommend_songs(song)\n",
    "#     output.update( {song : k})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame.from_dict(output, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Specify the number of clusters\n",
    "n_clusters = 4\n",
    "\n",
    "# Initialize the K-means model\n",
    "km = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "km.fit(X_train)\n",
    "\n",
    "# Predict the cluster labels for the training data\n",
    "train_labels = km.predict(X_train)\n",
    "\n",
    "# Predict the cluster labels for the test data\n",
    "test_labels = km.predict(X_test)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Fit the SVM model to the training data using the cluster labels as features\n",
    "svm.fit(train_labels.reshape(-1, 1), y_train)\n",
    "\n",
    "# Predict the class labels for the test data using the cluster labels as features\n",
    "y_pred = svm.predict(test_labels.reshape(-1, 1))\n",
    "\n",
    "# Calculate the accuracy of the SVM model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"The accuracy of the SVM model is {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
