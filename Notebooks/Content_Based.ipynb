{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(r\"datasets/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 15701)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer( stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "tracks['name'] = tracks['name'].fillna('')\n",
    "\n",
    "tracks = tracks.head(25000)\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(tracks['name'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices = pd.Series(tracks.index, index=tracks['name']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    idx = indices[title]\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    track_indices = [i[0] for i in sim_scores]\n",
    "    return tracks['name'].iloc[track_indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fall Back Down',\n",
       " 'Fall For You',\n",
       " 'I Might Fall Back On You',\n",
       " 'When I Fall In Love',\n",
       " 'When I Fall In Love',\n",
       " 'When I Fall In Love',\n",
       " 'When I Fall In Love',\n",
       " 'If I Ever Fall In Love',\n",
       " 'If I Ever Fall In Love',\n",
       " 'I Could Fall In Love']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"I Might Fall Back On You\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.to_csv('tracks_with_cluster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spotipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0851234b81a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspotipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspotipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moauth2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpotifyClientCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"677a46ed628944af94b5cdb96e3e25ee\",\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spotipy'"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"677a46ed628944af94b5cdb96e3e25ee\",\n",
    "                                                           client_secret=\"dfc3a58da7e34b009001ff1794592060\"))\n",
    "\n",
    "def find_song(name):\n",
    "    song_data = defaultdict()\n",
    "    results = sp.search(q= 'track: {}'.format(name), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "\n",
    "    results = results['tracks']['items'][0]\n",
    "    track_id = results['id']\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "\n",
    "    song_data['name'] = [name]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "    song_data['duration_ms'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "\n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "\n",
    "    return pd.DataFrame(song_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_data(song, spotify_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets the song data for a specific song. The song argument takes the form of a dictionary with \n",
    "    key-value pairs for the name and release year of the song.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['name'] == song['name']) ].iloc[0]\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError:\n",
    "        return find_song(song['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_algorithm(tracks):\n",
    "    num_datatypes = tracks.select_dtypes(np.number)      \n",
    "\n",
    "    pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "    song_embedding = pca_pipeline.fit_transform(num_datatypes)\n",
    "    return song_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_with_PCA_algorithm(song_embedding):\n",
    "    kmeans_pca = KMeans(n_clusters = 3, init = 'k-means++', random_state=42)    \n",
    "    return kmeans_pca.fit(song_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_based_on_segment(df_segm_pca_kmeans,segment_val):    \n",
    "    #get list of songs with above song id\n",
    "    #print(df_segm_pca_kmeans[df_segm_pca_kmeans['Segment K-means PCA']==segment_val].values)\n",
    "    \n",
    "    filtered_data_per_segment = df_segm_pca_kmeans[df_segm_pca_kmeans['Segment K-means PCA']==segment_val][['id', 'name','com1','com2','Segment K-means PCA']]\n",
    "\n",
    "    #save to csv file\n",
    "    filtered_data_per_segment.to_csv('filtered_data_per_segment.csv')\n",
    "    return filtered_data_per_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_based_on_cluster_centroid(kmeans_pca,filtered_data_per_segment,segment_val,tracks):\n",
    "    #calculate distance based on cluster centroid\n",
    "    scaled_data = kmeans_pca.transform( filtered_data_per_segment[['com1','com2']])\n",
    "    scaled_song_center = kmeans_pca.transform(kmeans_pca.cluster_centers_[segment_val].reshape(1, -1))\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "\n",
    "    #sort based on distance\n",
    "    index = list(np.argsort(distances)[0])\n",
    "    rec_songs = filtered_data_per_segment.iloc[index]\n",
    "    \n",
    "    #recommend based on segment data\n",
    "    # rec_songs = rec_songs[~rec_songs['name'].isin(filtered_data_per_segment['name'])]\n",
    "    return rec_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def recommend_songs(song_id, n_songs=10):\n",
    "  \n",
    "    \"\"\"\n",
    "    Recommends songs based on a list of previous songs that a user has listened to.\n",
    "    \"\"\"\n",
    "    song_embedding = PCA_algorithm(tracks)\n",
    "    \n",
    "    kmeans_pca = KMeans_with_PCA_algorithm(song_embedding)\n",
    "\n",
    "    #get Segment K-means PCA from song_id argument\n",
    "    df_segm_pca_kmeans = pd.concat([tracks.reset_index(drop=True), pd.DataFrame(song_embedding)],axis=1)\n",
    "    df_segm_pca_kmeans.columns.values[-2:] = ['com1','com2']\n",
    "    df_segm_pca_kmeans['Segment K-means PCA'] = kmeans_pca.labels_\n",
    "\n",
    "    #get segment value of song_id\n",
    "    segment_val = df_segm_pca_kmeans[df_segm_pca_kmeans['id'] == song_id]['Segment K-means PCA'].values[0]\n",
    "    \n",
    "    filtered_data_per_segment = filter_based_on_segment(df_segm_pca_kmeans,segment_val)   \n",
    "    \n",
    "    X = filtered_data_per_segment['com1']\n",
    "    y = filtered_data_per_segment['com2']\n",
    "    print(filtered_data_per_segment)\n",
    "\n",
    "    rec_songs = filter_based_on_cluster_centroid(kmeans_pca,filtered_data_per_segment,segment_val,tracks)\n",
    "\n",
    "    #recommend top n songs\n",
    "    return rec_songs.head(n_songs)['name'].tolist(), X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           id                             name      com1  \\\n",
      "1      7xPhfUan2yNtyFG0cUWkt8          Clancy Lowered the Boom  1.050906   \n",
      "9      08zfJvRLp7pjAb94MA9JmF                Il Etait Syndiqué  1.881899   \n",
      "10     0BMkRpQtDoKjcgzCpnqLNa  Dans La Vie Faut Pas S'en Faire  2.171411   \n",
      "14     0MJZ4hh60zwsYleWWxT5yW                   Power Is Power -0.690042   \n",
      "18     0QQmUf4aPFaN9U2yRko595                      When We Die  0.335485   \n",
      "...                       ...                              ...       ...   \n",
      "24989  6MMF38qO03XJ7puIxVl8Gg         I Might Fall Back On You  0.777417   \n",
      "24990  6SUXMuSUM01Ou6FRwKXyIc             Ella...La Que Se Fue  0.084604   \n",
      "24994  6kQ6pAESTDPwq1ZWrNHU42         Life On the Wicked Stage  1.696521   \n",
      "24998  7CZhyjk2lDW7A0lRsig45j    Where Will I Shelter My Sheep  0.999716   \n",
      "24999  7DvMNdb2kACIW4mO3MUqa3                         Cherokee  0.874801   \n",
      "\n",
      "           com2  Segment K-means PCA  \n",
      "1     -2.821883                    1  \n",
      "9     -2.385203                    1  \n",
      "10    -0.909158                    1  \n",
      "14    -1.172696                    1  \n",
      "18    -0.631702                    1  \n",
      "...         ...                  ...  \n",
      "24989 -1.213022                    1  \n",
      "24990 -0.154568                    1  \n",
      "24994 -0.226532                    1  \n",
      "24998 -0.687640                    1  \n",
      "24999 -0.054087                    1  \n",
      "\n",
      "[7662 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "rec_song, X, y = recommend_songs(\"3w3cxwYuR7ThpE8KVSys5x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listFrom1toN(n):\n",
    "    return list(range(1,n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7662\n",
      "7662\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 7662",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-c8730abdb372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 7662"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "result = np.vstack((X, y)).T\n",
    "\n",
    "X = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.05090562 -2.82188307]\n",
      " [ 1.88189933 -2.38520321]\n",
      " [ 2.17141059 -0.90915789]\n",
      " ...\n",
      " [ 1.69652077 -0.22653163]\n",
      " [ 0.99971613 -0.68764005]\n",
      " [ 0.87480095 -0.05408667]]\n",
      "7662\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "n = len(result)\n",
    "print(n)\n",
    "y = listFrom1toN(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# fig = px.scatter(projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r\"C:/Users/shris/Desktop/profiles.csv\")\n",
    "# print(df.gender)\n",
    "# df.columns = ['userid', 'gender', 'age', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs = df.gender.tolist()\n",
    "# output = {}\n",
    "# outputs = []\n",
    "# for song in songs:\n",
    "#     k = recommend_songs(song)\n",
    "#     output.update( {song : k})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame.from_dict(output, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Specify the number of clusters\n",
    "n_clusters = 4\n",
    "\n",
    "# Initialize the K-means model\n",
    "km = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "km.fit(X_train)\n",
    "\n",
    "# Predict the cluster labels for the training data\n",
    "train_labels = km.predict(X_train)\n",
    "\n",
    "# Predict the cluster labels for the test data\n",
    "test_labels = km.predict(X_test)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Fit the SVM model to the training data using the cluster labels as features\n",
    "svm.fit(train_labels.reshape(-1, 1), y_train)\n",
    "\n",
    "# Predict the class labels for the test data using the cluster labels as features\n",
    "y_pred = svm.predict(test_labels.reshape(-1, 1))\n",
    "\n",
    "# Calculate the accuracy of the SVM model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"The accuracy of the SVM model is {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
